{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import logging\n",
    "\n",
    "import ipywidgets\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "def update_progress(msg, progress):\n",
    "    barLength, status = 32, \"\"\n",
    "    block = int(round(barLength*progress))\n",
    "    text = \"\\r{0}: [{1}] {2:.2%} {3}\".format(msg, \"=\"*(block-1) + \">\" + \"-\"*(barLength-block), progress, status)\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(latent_dim):\n",
    "    encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "    x = keras.layers.Conv2D(32, 3, activation='relu', strides=2, padding='same')(encoder_inputs)\n",
    "    x = keras.layers.Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(16, activation='relu')(x)\n",
    "    z_mean = keras.layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = keras.layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(latent_dim):\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = keras.layers.Dense(7 * 7 * 64, activation='relu')(latent_inputs)\n",
    "    x = keras.layers.Reshape((7, 7, 64))(x)\n",
    "    x = keras.layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    x = keras.layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
    "    decoder_outputs = keras.layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name='decoder')\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.latent_dim = 2\n",
    "        self.n = 15\n",
    "        self.digit_size = 28\n",
    "        self.z_sample = [[xi,yi] for xi in np.linspace(-4, 4, self.n) for yi in np.linspace(-4, 4, self.n)[::-1]]\n",
    "        \n",
    "    def init(self, batch_size=128):\n",
    "        self.batch_size = batch_size\n",
    "        (x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "        mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "        mnist_digits = np.expand_dims(mnist_digits, -1).astype('float32') / 255\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(mnist_digits).batch(self.batch_size)\n",
    "        \n",
    "        self.encoder = build_encoder(self.latent_dim)\n",
    "        self.decoder = build_decoder(self.latent_dim)\n",
    "        \n",
    "        self.optimizer = keras.optimizers.Adam()\n",
    "        \n",
    "        self.digit_box = ipywidgets.Image()\n",
    "        self.digit_box.value = self.plot_images()\n",
    "        return self.digit_box\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(keras.losses.binary_crossentropy(data, reconstruction))\n",
    "            reconstruction_loss *= 28 * 28\n",
    "            kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "            kl_loss *= -0.5\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {'loss': total_loss,\n",
    "                'reconstruction_loss': reconstruction_loss,\n",
    "                'kl_loss': kl_loss}\n",
    "\n",
    "    def train(self, epochs, save_interval=10):\n",
    "        for e in range(epochs):\n",
    "            total_loss, recon_loss, kl_loss = [], [], []\n",
    "            counter = 0\n",
    "            for batch in self.dataset:\n",
    "                losses = self.train_step(batch)\n",
    "                total_loss.append(np.mean(losses['loss']))\n",
    "                recon_loss.append(np.mean(losses['reconstruction_loss']))\n",
    "                kl_loss.append(np.mean(losses['kl_loss']))\n",
    "                update_progress(\"Epoch {: 5d} | Losses: Total {: 6.2f} Reconstruction {: 6.2f} KL {: 6.4f}\".format(e,\n",
    "                    np.mean(total_loss),\n",
    "                    np.mean(recon_loss),\n",
    "                    np.mean(kl_loss)), self.batch_size * float(counter)/70000)\n",
    "                if counter % save_interval == 0:\n",
    "                    self.digit_box.value = self.plot_images()\n",
    "                counter += 1\n",
    "            print()\n",
    "    \n",
    "    def plot_images(self):\n",
    "        canvas = PIL.Image.new('RGB', (self.n*self.digit_size, self.n*self.digit_size), color='white')\n",
    "        x_decoded = 255 * self.decoder.predict(self.z_sample)[:,:,:,0]\n",
    "        for i,d in enumerate(x_decoded):\n",
    "            dimg = PIL.Image.fromarray(d.astype('uint8')).resize((self.digit_size, self.digit_size), resample=PIL.Image.NEAREST)\n",
    "            canvas.paste(dimg, box=(self.digit_size*int(i/self.n), self.digit_size*int(i%self.n)))\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        canvas.save(buf, 'gif')\n",
    "        return buf.getvalue()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_box = vae.init(batch_size=256)\n",
    "display(digit_box)\n",
    "vae.train(epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
